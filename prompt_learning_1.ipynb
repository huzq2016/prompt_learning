{
 "cells": [
  {
   "cell_type": "raw",
   "id": "079d2dd1",
   "metadata": {},
   "source": [
    "from https://savasy-22028.medium.com/prompting-in-nlp-prompt-based-zero-shot-learning-3f34bfdb2b72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4bdef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM , AutoTokenizer\n",
    "import torch\n",
    "model_path=\"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e28e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from prompt import Prompting\n",
    "prompting= Prompting(model=model_path)\n",
    "prompt=\"Because it was [MASK].\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b53cfad",
   "metadata": {},
   "source": [
    "From python3.3 upwards, __init__.py is no longer necessary. If the current directory of the console is the directory where the python script is located, everything works fine with\n",
    "\n",
    "import user\n",
    "However, this won't work if called from a different directory, which does not contain user.py.\n",
    "In that case, use\n",
    "\n",
    "from . import user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68401812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', tensor(9.5558)),\n",
       " ('amazing', tensor(9.2532)),\n",
       " ('good', tensor(9.1464)),\n",
       " ('fun', tensor(8.3979)),\n",
       " ('fantastic', tensor(8.3277)),\n",
       " ('wonderful', tensor(8.2719)),\n",
       " ('beautiful', tensor(8.1584)),\n",
       " ('awesome', tensor(8.1071)),\n",
       " ('incredible', tensor(8.0140)),\n",
       " ('funny', tensor(7.8785))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s Pass a positive sentence\n",
    "text=\"I really like the film a lot.\"\n",
    "prompting.prompt_pred(text+prompt)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ef1e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bad', tensor(8.6784)),\n",
       " ('funny', tensor(8.1660)),\n",
       " ('good', tensor(7.9858)),\n",
       " ('awful', tensor(7.7454)),\n",
       " ('scary', tensor(7.3526)),\n",
       " ('boring', tensor(7.1553)),\n",
       " ('wrong', tensor(7.1402)),\n",
       " ('terrible', tensor(7.1296)),\n",
       " ('horrible', tensor(6.9923)),\n",
       " ('ridiculous', tensor(6.7731))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing a negative sentence:\n",
    "text=\"I did not like the film.\"\n",
    "prompting.prompt_pred(text+prompt)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04caa8",
   "metadata": {},
   "source": [
    "# Producing the results based on a list of neg/pos words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53308b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1496, 0.8504])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"not worth watching\"\n",
    "prompting.compute_tokens_prob(text+prompt, token_list1=[\"great\",\"amazin\",\"good\"], token_list2= [\"bad\",\"awfull\",\"terrible\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a63255",
   "metadata": {},
   "source": [
    "# Unbiasing the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29927799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8495, 0.1505])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompting.compute_tokens_prob(\"it was \"+ prompting.tokenizer.mask_token +\".\", token_list1=[\"good\"], token_list2= [\"bad\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f264838",
   "metadata": {},
   "source": [
    "# Name Entity Recognition in zero-shot setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7dd210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', tensor(8.1382)),\n",
       " ('john', tensor(7.1325)),\n",
       " ('guy', tensor(6.9672)),\n",
       " ('writer', tensor(6.4336)),\n",
       " ('philosopher', tensor(6.3823))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompting.prompt_pred(\"John went to Paris to visit the University. John is a type of [MASK].\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a40abd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('philosopher', tensor(7.6558)),\n",
       " ('poet', tensor(7.5621)),\n",
       " ('saint', tensor(7.0104)),\n",
       " ('man', tensor(6.8890)),\n",
       " ('pigeon', tensor(6.6780))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompting.prompt_pred('Savaş went to Paris to visit the university. Savaş is a type of [MASK].')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f75a3fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7603, 0.2397])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompting.compute_tokens_prob('It is a type of [MASK].', token_list1=[\"person\",\"man\"], token_list2=[\"location\",\"city\",\"place\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97a14bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.9987e-01, 1.2744e-04])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompting.compute_tokens_prob(\"Savaş went to Paris to visit the parliament. Savaş is a type of [MASK].\",  token_list1=[\"person\",\"man\"], token_list2=[\"location\",\"city\",\"place\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "782f949f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3263, 0.6737])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompting.compute_tokens_prob(\"Savaş went to Laris to visit the parliament. Laris is a type of [MASK].\",  token_list1=[\"person\",\"man\"], token_list2=[\"location\",\"city\",\"place\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfc057a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5516, 0.4484])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompting.compute_tokens_prob(\"Savas went to XYZ to visit friends. XYZ is a type of [MASK].\", token_list1=[\"person\",\"man\"], token_list2=[\"location\",\"city\",\"place\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f510ef84",
   "metadata": {},
   "source": [
    "# Topic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4333b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mathematics', tensor(8.8438)),\n",
       " ('computer', tensor(7.9713)),\n",
       " ('programming', tensor(7.7146)),\n",
       " ('computing', tensor(7.6635)),\n",
       " ('math', tensor(7.5142)),\n",
       " ('algebra', tensor(7.1716)),\n",
       " ('computers', tensor(7.0012)),\n",
       " ('game', tensor(6.9694)),\n",
       " ('physics', tensor(6.9225)),\n",
       " ('computation', tensor(6.8152))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompting.prompt_pred(\"Savas went to Paris to study computer science. he started to learn basic staff like programming, algorithm, operating systemvisit the parliament. The topic is a type of [MASK].\")[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ada93c",
   "metadata": {},
   "source": [
    "# Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcaa3136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "fe=pipeline(\"feature-extraction\", model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c496ac2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"the film is ok. it means [MASK].\"\n",
    "indexed_tokens= tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "tokenized_text= tokenizer.convert_ids_to_tokens (indexed_tokens[0])\n",
    "mask_pos= (indexed_tokens[0]== tokenizer.mask_token_id).nonzero().item()\n",
    "text_emb=fe(text)\n",
    "mask_emb=text_emb[0][mask_pos]\n",
    "len(mask_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb47e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
